# Visual-Question-Answering-App
**Visual Question Answering (VQA) App**

A simple Multimodal AI application that lets you upload an image and ask a question about it.
Powered by HuggingFace Transformers, ViLT (Vision-and-Language Transformer), and Gradio.

This project demonstrates how to combine images + text and generate intelligent answers using a pretrained model.

**ðŸš€ Features**

Upload any image (JPG/PNG/WebP)

Ask natural-language questions

AI model analyzes both image contents and your text

Real-time predictions in a clean Gradio web UI

Runs completely on your system using PyTorch CPU/GPU

Visual Question Answering (VQA) App

A simple Multimodal AI application that lets you upload an image and ask a question about it.
Powered by HuggingFace Transformers, ViLT (Vision-and-Language Transformer), and Gradio.

This project demonstrates how to combine images + text and generate intelligent answers using a pretrained model.

**ðŸš€ Features**

Upload any image (JPG/PNG/WebP)

Ask natural-language questions

AI model analyzes both image contents and your text

Real-time predictions in a clean Gradio web UI

Runs completely on your system using PyTorch CPU/GPU

**ðŸ§  Model Used**

This project uses:

ViLT (dandelin/vilt-b32-finetuned-vqa)

A transformer architecture for vision + language

Pretrained on large VQA datasets

Fast and lightweight compared to ViLBERT/CLIP-like modelsðŸ§  Model Used**

This project uses:

ViLT (dandelin/vilt-b32-finetuned-vqa)

A transformer architecture for vision + language

Pretrained on large VQA datasets

Fast and lightweight compared to ViLBERT/CLIP-like models
